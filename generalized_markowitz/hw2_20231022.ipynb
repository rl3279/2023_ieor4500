{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "def evalfunc(portfolio: np.ndarray, ret: np.ndarray, pi: float, theta: float) -> float:\n",
    "    \"\"\"\n",
    "    Task 1: the objective function\n",
    "    (Remember to vectorize as much as possible)\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    portfolio: np.ndarray: the portfolio vector i.e. x\n",
    "\n",
    "    ret: np.ndarray: the (T, 3) numpy array containing all asset returns\n",
    "\n",
    "    pi: float: the exponent parameter of the objective\n",
    "\n",
    "    theta: the risk-aversion parameter of the objective\n",
    "\n",
    "\n",
    "    Returns\n",
    "    --------------\n",
    "    float: the objective value.\n",
    "    \"\"\"\n",
    "    # compute mean returns first. ret_mu shape should be (3,)\n",
    "    ret_mu = ret.mean(axis=0)\n",
    "\n",
    "    portfolio = np.append(portfolio, [1-portfolio.sum()])\n",
    "\n",
    "    # first part\n",
    "    drift = -ret_mu.dot(portfolio)\n",
    "\n",
    "    # second part\n",
    "    # weighed deviation from mean (part within []^pi)\n",
    "    deviation = np.abs((ret - ret_mu).dot(portfolio))\n",
    "    risk = theta * (\n",
    "        (deviation**pi).mean()\n",
    "    )**(1/pi)\n",
    "    return drift + risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider that since $\\textbf{x}$ is by nature a vector of portfolio weights, hence it must sum to $1$. Then, set $x_c = 1-\\sum_{j\\neq c} x_j$, we have new objective function with $|\\textbf{x}|=c-1$:\n",
    "\\begin{align*}\n",
    "\\min -\\sum_{j\\neq c} \\bar{r}_jx_j - \\bar{r}_cx_c + \\theta\\left(\n",
    "\t\\frac{1}{T}\\sum_{t=1}^T\\left[\n",
    "\t\t\\sum_{j\\neq c} ((r_{j,t}-\\bar{r}_j)x_j)\n",
    "\t\t+(r_{c,t}-\\bar{r}_c)x_c\n",
    "\t\\right]^\\pi\n",
    "\\right)^{1/\\pi}\n",
    "\\end{align*}\n",
    "Alternatively, in matrix notation, with \\textbf{r} denoting the return matrix without the last column, $r_c$, \n",
    "\\begin{align*}\n",
    "\\min -(\\bar{\\textbf{r}}-\\bar{r_c}'\\textbf{1})'\\textbf{x}-\\bar{r}_c+\\frac{\\theta}{T^{1/\\pi}}||(\\tilde{\\textbf{r}}-\\tilde{r}_c)'\\textbf{x} + \\tilde{r}_c'\\textbf{1}||_\\pi\n",
    "\\end{align*}\n",
    "where $\\tilde{x} = x - \\bar{x}$. Using the identity\n",
    "\\begin{align*}\n",
    "\\frac{\\partial ||\\textbf{x}||_p}{\\partial \\textbf{x}}&=\\frac{\\textbf{x}\\circ |\\textbf{x}|^{p-2}}{||\\textbf{x}||_p^{p-1}}\n",
    "\\end{align*}\n",
    "we easily see\n",
    "\\begin{align*}\n",
    "\\nabla \\textbf{x} &= (-\\bar{\\textbf{r}} - \\textbf{1}'\\bar{r}_c) + \\frac{\\theta}{T^{1/\\pi}}\\cdot \n",
    "\\frac{\\textbf{D}\\circ |\\textbf{D}|^{\\pi-2}}{||\\textbf{D}||_\\pi^{\\pi-1}}\\cdot \\nabla\\textbf{D}\\\\\n",
    "\\text{where}\\quad \\textbf{D}&=(\\tilde{\\textbf{r}}-\\tilde{r}_c)'\\textbf{x} + \\tilde{r}_c'\\textbf{1}\\\\\n",
    "\\nabla\\textbf{D}&=\\tilde{\\textbf{r}} - \\tilde{r}_c\\\\\n",
    "&=(\\textbf{r} - \\bar{\\textbf{r}})-(r_c-\\bar{r}_c)\n",
    "\\end{align*}\n",
    "In the case of this particular study, there are two decision variables and $c=3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalgrad(x, ret, pi, theta):\n",
    "    # extract dimension\n",
    "    T = ret.shape[0]\n",
    "\n",
    "    # compute mean return\n",
    "    ret_mu = ret.mean(axis = 0)\n",
    "\n",
    "    # compute excess return\n",
    "    delta = ret - ret_mu\n",
    "\n",
    "    # split last mean return and last excess\n",
    "    ret_mu, ret_mu_c = ret_mu[:-1], ret_mu[-1]\n",
    "    delta, delta_c = delta[:, :-1], delta[:, -1].reshape(-1, 1)\n",
    "\n",
    "    # deviation from mean\n",
    "    dev = (delta - delta_c).dot(x).reshape(-1,1) + delta_c\n",
    "\n",
    "    # dev gradient\n",
    "    nom = dev * np.absolute(dev)**(pi-2)\n",
    "    denom = ((np.absolute(dev)**pi).sum())**(1-1/pi)\n",
    "    return -(ret_mu-ret_mu_c) + (\n",
    "        (theta / T**(1/pi))*nom/denom\n",
    "    ).T.dot(delta - delta_c).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrack(\n",
    "        x:np.ndarray, ret:np.ndarray, \n",
    "        pi:float , theta:float, fval:float, grad:np.ndarray, delta:np.ndarray,\n",
    "        alpha:float = 0.5, beta:float = 0.75, step_eps:float=1e-4,\n",
    "        init_step:float = 1\n",
    "    ) -> Tuple[float, bool]:\n",
    "    \"\"\"\n",
    "    Task 1: backtrack step finder\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    x: np.ndarray: portfolio weights\n",
    "\n",
    "    ret: np.ndarray: return matrix\n",
    "\n",
    "    pi: float: the exponent parameter of the objective\n",
    "\n",
    "    theta: the risk-aversion parameter of the objective\n",
    "\n",
    "    fval: float: current functional value\n",
    "\n",
    "    grad: np.ndarray: gradient\n",
    "\n",
    "    delta: np.ndarray: direction vector\n",
    "\n",
    "    alpha: float: acceptance threshold\n",
    "\n",
    "    beta: float: shrink ratio\n",
    "\n",
    "    step_eps: float: the tolerance lower bound of backtrack step\n",
    "\n",
    "    init_step: float: intial step size\n",
    "\n",
    "\n",
    "    Returns\n",
    "    --------------\n",
    "    Tuple[float, bool]: optimal step size, success boolean\n",
    "    \"\"\"\n",
    "    grad_dot_delta = grad.dot(delta)\n",
    "    step = init_step\n",
    "    goon = True\n",
    "    success = False\n",
    "    \n",
    "    while goon:\n",
    "        fnew = evalfunc(x + step * delta, ret, pi, theta)\n",
    "        target = alpha * step * grad_dot_delta\n",
    "\n",
    "        if fnew - fval <= target:\n",
    "            goon = False\n",
    "            success = True\n",
    "        else:\n",
    "            step *= beta\n",
    "        if step < step_eps:\n",
    "            goon = False\n",
    "    return step, success\n",
    "\n",
    "def get_descent(\n",
    "    step: float, \n",
    "    grad: np.ndarray,\n",
    "    momentum: bool = False,\n",
    "    olddelta: np.ndarray = None,\n",
    "    mu: float = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Task 1: helper function to generate the descent step,\n",
    "    for both momentum and non-momentum case.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    step: float: step size\n",
    "\n",
    "    grad: np.ndarray: gradient\n",
    "\n",
    "    momentum: bool: momentum flag\n",
    "\n",
    "    olddelta: np.ndarray: moving average vector for momentum\n",
    "\n",
    "    mu: float: conservation parameter for momentum descent\n",
    "\n",
    "    Returns\n",
    "    --------------\n",
    "    np.ndarray: descent step\n",
    "    \"\"\"\n",
    "    if not momentum:\n",
    "        # if not momentum just negative gradient direction times step size\n",
    "        return - step * grad\n",
    "    else:\n",
    "        # if momentum the convex combination of moving average and conventional step\n",
    "        assert (olddelta is not None) and (mu is not None)\n",
    "        return -mu * step * grad + (1-mu) * olddelta\n",
    "\n",
    "\n",
    "\n",
    "def run_grad_desc(\n",
    "    x: np.ndarray,\n",
    "    ret: np.ndarray,\n",
    "    pi: float, \n",
    "    theta: float,\n",
    "    x_history: np.ndarray,\n",
    "    f_history: np.ndarray,\n",
    "    bt: bool = True,\n",
    "    bt_a: float = None,\n",
    "    bt_b: float = None,\n",
    "    bt_init_step: float = 1,\n",
    "    momentum: bool = False,\n",
    "    mom_mu: float = None,\n",
    "    max_iter: int = 1000,\n",
    "    step_eps: float = 0.05,\n",
    ") -> Tuple[bool, np.ndarray]:\n",
    "    converged = False\n",
    "    iter = 0\n",
    "    descent = np.zeros_like(x)\n",
    "    while iter < max_iter:\n",
    "        x_history[iter] = x\n",
    "        fval = evalfunc(x, ret, pi, theta)\n",
    "        grad = evalgrad(x, ret, pi, theta)\n",
    "        f_history[iter] = fval  \n",
    "        if bt:\n",
    "            # if backtrack, call backtrack function to compute step size\n",
    "            step, goodstep = backtrack(x, ret, pi, theta, fval, grad, -grad, bt_a, bt_b, step_eps, bt_init_step)\n",
    "            goodstep = True\n",
    "        else:\n",
    "            # if not, use constant step size\n",
    "            goodstep = True\n",
    "            step = step_eps\n",
    "\n",
    "        # one line to deal with both momentum and non-momentum case\n",
    "        descent = get_descent(step, grad, momentum, descent, mom_mu)\n",
    "        if goodstep:\n",
    "            # if good step, descend\n",
    "            x += descent\n",
    "            \n",
    "            if np.isclose(grad, 0).all():\n",
    "                converged = True\n",
    "                print(\"Converged. x:\", x)\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "                # if iter % 10 == 0:\n",
    "                #     print(f\"grad {iter} = {grad}\")\n",
    "                #     print(f\"grad L2 {iter} = {np.inner(grad, grad)}\")\n",
    "        iter += 1\n",
    "    return iter, converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-b656fab1af73>:76: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  read_asset(\"AMZN\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMZN_ret</th>\n",
       "      <th>AMZN_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>-0.027139</td>\n",
       "      <td>3262.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>0.006993</td>\n",
       "      <td>3174.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>0.010673</td>\n",
       "      <td>3146.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>0.010303</td>\n",
       "      <td>3162.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>-0.005051</td>\n",
       "      <td>3173.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07</th>\n",
       "      <td>-0.004655</td>\n",
       "      <td>3729.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08</th>\n",
       "      <td>0.004955</td>\n",
       "      <td>3652.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09</th>\n",
       "      <td>0.002678</td>\n",
       "      <td>3718.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12</th>\n",
       "      <td>-0.011032</td>\n",
       "      <td>3746.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-13</th>\n",
       "      <td>0.011858</td>\n",
       "      <td>3708.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AMZN_ret  AMZN_price\n",
       "Date                            \n",
       "2021-01-04 -0.027139     3262.80\n",
       "2021-01-05  0.006993     3174.80\n",
       "2021-01-06  0.010673     3146.17\n",
       "2021-01-07  0.010303     3162.20\n",
       "2021-01-08 -0.005051     3173.77\n",
       "...              ...         ...\n",
       "2021-07-07 -0.004655     3729.24\n",
       "2021-07-08  0.004955     3652.90\n",
       "2021-07-09  0.002678     3718.54\n",
       "2021-07-12 -0.011032     3746.21\n",
       "2021-07-13  0.011858     3708.82\n",
       "\n",
       "[130 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def is_open_or_noon(dt: datetime.datetime) -> bool:\n",
    "    t = dt.time()\n",
    "    return t == datetime.time(9,30) or t == datetime.time(12,0)\n",
    "\n",
    "def is_open(dt:datetime.datetime) -> bool:\n",
    "    return dt.time() == datetime.time(9,30)\n",
    "\n",
    "def my_dt_parser(s: str) -> datetime.datetime:\n",
    "    date, time = s.split()\n",
    "    m, d, y = date.split(\"/\")\n",
    "    H, M = time.split(\":\")\n",
    "    return datetime.datetime(\n",
    "        year = 2000 + int(y),\n",
    "        month = int(m),\n",
    "        day = int(d),\n",
    "        hour = int(H),\n",
    "        minute = int(M)\n",
    "    )\n",
    "\n",
    "def read_asset(asset:str, data_dir: str=\"../data/\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Task 1: reads a single asset.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    csv_path: str: relative path of the csv file containing desired asset.\n",
    "\n",
    "    return_price: bool: flag to return price along with returns. This is\n",
    "    needed for test data for computing number of shares to trade at market open.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    --------------\n",
    "    pd.DataFrame: pandas dataframe containing asset returns\n",
    "    \"\"\"\n",
    "    # static var to mark missing data\n",
    "    missing = -999.\n",
    "    # read csv\n",
    "    csv_path = data_dir + asset + \".csv\"\n",
    "    df = pd.read_csv(csv_path, header=3).loc[:, [\"Dates\", \"Close\"]]\n",
    "    # read up to empty entries\n",
    "    df = df.iloc[:df[\"Close\"].isna().argmax()]\n",
    "    \n",
    "    # \n",
    "    df.loc[0,\"Dates\"] = df.loc[1,\"Dates\"].replace(\"31\", \"30\")\n",
    "\n",
    "    # extract open or noon data\n",
    "    df[\"dt\"] = df[\"Dates\"].apply(my_dt_parser)\n",
    "    df[\"Date\"] = df[\"dt\"].apply(lambda dt: dt.date())\n",
    "    open_or_noon = df[\"dt\"].apply(is_open_or_noon)\n",
    "    df = df.loc[open_or_noon]\n",
    "\n",
    "    # compute daily return\n",
    "    # ret = df.loc[:, [\"Close\",\"Date\"]].groupby(\"Date\").pct_change().values\n",
    "    ret = df.loc[:, [\"Close\",\"Date\"]].groupby(\"Date\").apply(\n",
    "        # lambda x: x[1]/x[0]-1 if len(x) == 2 else np.nan\n",
    "        lambda x: x[\"Close\"].iloc[1]/x[\"Close\"].iloc[0]-1 if len(x) == 2 else missing\n",
    "    ).values\n",
    "\n",
    "    ret = ret[~np.isnan(ret)]\n",
    "\n",
    "    # return along with daily open price\n",
    "    df = df.loc[df[\"dt\"].apply(is_open)]\n",
    "    df[\"ret\"] = ret\n",
    "    # filter out bad dates with missing data\n",
    "    df = df.loc[df.ret > missing + 1]\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    df = df[[\"ret\", \"Close\"]]\n",
    "    df.rename(columns = {\"ret\": f\"{asset}_ret\", \"Close\": f\"{asset}_price\"}, inplace = True)\n",
    "    return df\n",
    "\n",
    "read_asset(\"AMZN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-a039edf8624d>:17: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [read_asset(asset, data_dir) for asset in assets]\n"
     ]
    }
   ],
   "source": [
    "def read_all(data_dir: str = \"../data/\", T: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Task 1.5: reads all asset returns and sever into train and test.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    T: int: size of the traning period.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    --------------\n",
    "    pd.DataFrame: pandas dataframe containing asset returns\n",
    "    \"\"\"\n",
    "    assets = [\"AMZN\", \"NFLX\", \"TSLA\"]\n",
    "\n",
    "    dfs = [read_asset(asset, data_dir) for asset in assets]\n",
    "\n",
    "    df = dfs[0]\n",
    "    for i in range(1, 3):\n",
    "        df = df.join(dfs[i])\n",
    "    df = df.dropna()\n",
    "    return df.iloc[:T], df.iloc[T:]\n",
    "\n",
    "train, test = read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_train = train.loc[:,[col for col in train.columns if \"ret\" in col]]\n",
    "price_train = train.loc[:,[col for col in train.columns if \"price\" in col]]\n",
    "ret_test = test.loc[:,[col for col in test.columns if \"ret\" in col]].values\n",
    "price_test= test.loc[:,[col for col in test.columns if \"price\" in col]].values\n",
    "\n",
    "# Task 2\n",
    "def benchmark(ret_test: np.ndarray, price_test: np.ndarray, x: np.ndarray):\n",
    "    p0 = 1e9\n",
    "    shares = p0 / np.abs(x).sum() * x / price_test\n",
    "    portfolio_return = ret_test.dot(x).mean()\n",
    "    return shares, portfolio_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged: False, after 10000 iterations\n"
     ]
    }
   ],
   "source": [
    "ret = ret_train.values\n",
    "pi = 2; theta = 1e6; portfolio = np.array([1/3, 1/3])\n",
    "max_iter = 10000\n",
    "m = len(portfolio)\n",
    "x_history = np.zeros((max_iter, m))\n",
    "f_history = np.zeros(max_iter)\n",
    "it, converged = run_grad_desc(\n",
    "    x = portfolio, \n",
    "    ret = ret, \n",
    "    pi = pi, theta = theta, x_history = x_history, f_history = f_history,\n",
    "    bt=True, bt_a=0.5, bt_b=0.75, bt_init_step=1,\n",
    "    momentum=False, mom_mu=0.8, \n",
    "    max_iter = max_iter, step_eps=1e-4, \n",
    ")\n",
    "\n",
    "print(f\"Converged: {str(converged)}, after {it} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final objective = 30639.52616\n",
      "Final portfolio = [1.4509, 1.07609, -1.52699]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pi = 2, Theta = 1000000.0,\\nFinal portfolio = [1.4509, 1.07609, -1.52699]')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize= (15, 5))\n",
    "\n",
    "ax[0].plot(f_history[:it])\n",
    "portfolio_history = np.hstack([x_history, (1 - x_history.sum(axis = 1)).reshape(-1, 1)])\n",
    "ax[1].plot(portfolio_history[:it])\n",
    "\n",
    "final_objective = round(f_history[it-1],5)\n",
    "final_portfolio = [round(p,5) for p in portfolio_history[it-1]]\n",
    "print(f\"Final objective = {final_objective}\")\n",
    "print(f\"Final portfolio = {final_portfolio}\")\n",
    "\n",
    "ax[0].set_title(f\"Pi = {pi}, Theta = {theta},\\nFinal objective = {final_objective} at iter {it}.\")\n",
    "ax[1].set_title(f\"Pi = {pi}, Theta = {theta},\\nFinal portfolio = {final_portfolio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 104648.02652027,  500641.98801266, -560504.1796054 ],\n",
       "        [ 104060.47864945,  499267.16706977, -549915.19634517],\n",
       "        [ 103889.81094619,  498086.73355159, -551929.68530533],\n",
       "        [ 104025.99790116,  504198.57547451, -550119.19704018],\n",
       "        [ 103728.11919447,  494081.56884132, -553056.13857314],\n",
       "        [ 100826.05911576,  497591.86811194, -550856.14340376],\n",
       "        [  95970.01110657,  489282.00778661, -568447.09446836],\n",
       "        [  97975.63695121,  499192.0525902 , -599649.46363416],\n",
       "        [  96246.16226236,  500500.39039184, -574017.30251394],\n",
       "        [  95535.27544347,  493090.32182403, -567348.56407732],\n",
       "        [  96498.40224628,  494311.59247716, -547126.64373073]]),\n",
       " 0.006079688139767474)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(ret_test, price_test, np.array(final_portfolio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=0.5, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=0.5, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=0.5, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=0.5, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=2, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=2, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=2, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=2, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=4, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=4, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [1.15430262 0.31894751]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=4, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [1.15430262 0.31894752]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [1.15430262 0.31894752]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [1.15430261 0.31894752]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=4, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [1.15430261 0.31894752]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [1.15430261 0.31894752]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [1.1543026  0.31894753]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=6, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [1.15572409 0.26562637]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=6, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [1.1557241  0.26562636]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=6, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [1.1557241  0.26562636]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [1.1557241  0.26562636]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [1.15572411 0.26562635]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=0.1, pi=6, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [1.15572411 0.26562635]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [1.15572411 0.26562635]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [1.15572412 0.26562634]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=0.5, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=0.5, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=0.5, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=0.5, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=2, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.75223546 0.32162641]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=2, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.75223545 0.32162642]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=2, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.75223545 0.32162642]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.75223545 0.32162642]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.75223544 0.32162643]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=2, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.75223544 0.32162643]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.75223544 0.32162643]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.75223543 0.32162643]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=4, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.82173982 0.26484497]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=4, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.82173982 0.26484496]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=4, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.82173983 0.26484496]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.82173983 0.26484496]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.82173983 0.26484495]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=4, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.82173983 0.26484495]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.82173983 0.26484495]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.82173984 0.26484495]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=6, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.91636167 0.17405783]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=6, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.91636168 0.17405782]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=6, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.91636168 0.17405782]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.91636168 0.17405782]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.91636168 0.17405781]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=10, pi=6, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.91636168 0.17405781]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.91636168 0.17405781]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.91636169 0.17405781]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=0.5, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=0.5, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=0.5, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=0.5, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=2, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.74881535 0.3215212 ]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=2, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.74881534 0.32152119]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=2, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.74881534 0.32152119]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.74881534 0.32152119]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.74881534 0.32152119]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=2, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.74881535 0.32152119]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.74881534 0.3215212 ]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=4, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.81797031 0.26595411]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=4, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.81797031 0.26595411]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=4, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.81797031 0.26595411]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.81797031 0.26595411]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.81797031 0.26595411]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=4, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.81797031 0.26595411]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.81797032 0.2659541 ]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=6, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.91318472 0.17504067]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=6, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.91318472 0.17504067]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=6, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "Converged. x: [0.91318472 0.17504067]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.91318472 0.17504067]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.91318472 0.17504068]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000, pi=6, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "Converged. x: [0.91318472 0.17504067]\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "Converged. x: [0.91318472 0.17504067]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=0.5, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=0.5, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=0.5, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=0.5, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=2, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.74878115 0.32152014]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=2, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.74878114 0.32152014]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=2, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=2, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=4, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.81793248 0.26596536]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=4, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.81793248 0.26596536]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=4, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=4, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=6, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "Converged. x: [0.9131528  0.17505075]\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=6, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=6, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=100000, pi=6, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=0.5, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=0.5, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=0.5, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=0.5, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=2, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=2, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=2, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=2, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=4, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=4, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=4, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=4, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=6, bt=True, mom=True...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=6, bt=True, mom=False...\n",
      "\tstep_eps: 0.0001\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=6, bt=False, mom=True...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n",
      "************************************************************\n",
      "RUNNING: theta=1000000, pi=6, bt=False, mom=False...\n",
      "\tstep_eps: 0.1\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 0.01\n",
      "************************************************************\n",
      "\n",
      "\tstep_eps: 1\n",
      "************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup looping\n",
    "\n",
    "result = []\n",
    "\n",
    "thetas = [10**i for i in [-1, 1, 3, 5, 6]]\n",
    "pis = [0.5, 2, 4, 6]\n",
    "bts = [True, False]\n",
    "moms = [True, False]\n",
    "portfolio = np.array([1/3, 1/3])\n",
    "\n",
    "max_iter = 11000\n",
    "m = len(portfolio)\n",
    "ret = ret_train.values\n",
    "\n",
    "\n",
    "loud = True\n",
    "\n",
    "for theta in thetas:\n",
    "    for pi in pis:\n",
    "          for bt in bts:\n",
    "                for mom in moms:\n",
    "                    if loud:\n",
    "                        print(\"*\"*60)\n",
    "                        print(f\"RUNNING: theta={theta}, pi={pi}, bt={bt}, mom={mom}...\")\n",
    "                    \n",
    "                    if bt:\n",
    "                        step_epss = [1e-4]\n",
    "                    else:\n",
    "                        step_epss = [0.1, 0.01, 1]\n",
    "                        step_epss\n",
    "                    for step_eps in step_epss:\n",
    "                        if loud:\n",
    "                            print(\"\\tstep_eps:\", step_eps)\n",
    "                        x_history = np.zeros((max_iter, m))\n",
    "                        f_history = np.zeros(max_iter)\n",
    "                        it, converged = run_grad_desc(\n",
    "                            x = portfolio, \n",
    "                            ret = ret, \n",
    "                            pi = pi, theta = theta, x_history = x_history, f_history = f_history,\n",
    "                            bt=bt, bt_a=0.5, bt_b=0.75, momentum=mom, mom_mu=0.8, \n",
    "                            max_iter = max_iter, step_eps=step_eps, \n",
    "                        )\n",
    "                        portfolio_history = np.hstack([x_history, (1 - x_history.sum(axis = 1)).reshape(-1, 1)])\n",
    "                        final_objective = f_history[it-1]\n",
    "                        final_portfolio = portfolio_history[it-1]\n",
    "                        result.append(\n",
    "                            {\n",
    "                                \"theta\": theta,\n",
    "                                \"pi\": pi,\n",
    "                                \"backtrack\": bt,\n",
    "                                \"momentum\": mom,\n",
    "                                \"step_size/step_eps\": step_eps,\n",
    "                                \"converged\": converged,\n",
    "                                \"converged_iter\": it,\n",
    "                                \"final_objective\": final_objective,\n",
    "                                \"final_portfolio\": final_portfolio\n",
    "                            }\n",
    "                        )\n",
    "                        if loud:\n",
    "                            print(\"*\"*60)\n",
    "                            print()\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>pi</th>\n",
       "      <th>backtrack</th>\n",
       "      <th>momentum</th>\n",
       "      <th>step_size/step_eps</th>\n",
       "      <th>converged</th>\n",
       "      <th>converged_iter</th>\n",
       "      <th>final_objective</th>\n",
       "      <th>final_portfolio</th>\n",
       "      <th>portfolio_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>4.966088e-04</td>\n",
       "      <td>[0.6745018704862605, 0.6141752435072398, -0.28...</td>\n",
       "      <td>0.002649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>4.962833e-04</td>\n",
       "      <td>[0.6750016447446546, 0.6137394069694466, -0.28...</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>3.583341e-06</td>\n",
       "      <td>[1.2697421550470593, 0.9275339761371483, -1.19...</td>\n",
       "      <td>0.005212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>-5.723917e-05</td>\n",
       "      <td>[1.3346661236282955, 0.9702820869689304, -1.30...</td>\n",
       "      <td>0.005506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>-3.638080e-03</td>\n",
       "      <td>[6.946014648591141, 3.3590638223388023, -9.305...</td>\n",
       "      <td>0.028748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>1.060783e+07</td>\n",
       "      <td>[-142.38408408662656, -161.69058299251708, 305...</td>\n",
       "      <td>-0.755969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>1.856815e+09</td>\n",
       "      <td>[25016.68903235549, 28419.948008131727, -53435...</td>\n",
       "      <td>132.720764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>1.362941e+08</td>\n",
       "      <td>[1836.769624181739, 2086.7015462514073, -3922....</td>\n",
       "      <td>9.744059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>1.593999e+07</td>\n",
       "      <td>[215.2839079913253, 244.63441958252952, -458.9...</td>\n",
       "      <td>1.141572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>11000</td>\n",
       "      <td>2.209946e+09</td>\n",
       "      <td>[29774.283339476537, 33824.75294087074, -63598...</td>\n",
       "      <td>157.961289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         theta   pi  backtrack  momentum  step_size/step_eps  converged  \\\n",
       "0          0.1  0.5       True      True              0.0001      False   \n",
       "1          0.1  0.5       True     False              0.0001      False   \n",
       "2          0.1  0.5      False      True              0.1000      False   \n",
       "3          0.1  0.5      False      True              0.0100      False   \n",
       "4          0.1  0.5      False      True              1.0000      False   \n",
       "..         ...  ...        ...       ...                 ...        ...   \n",
       "155  1000000.0  6.0      False      True              0.0100      False   \n",
       "156  1000000.0  6.0      False      True              1.0000      False   \n",
       "157  1000000.0  6.0      False     False              0.1000      False   \n",
       "158  1000000.0  6.0      False     False              0.0100      False   \n",
       "159  1000000.0  6.0      False     False              1.0000      False   \n",
       "\n",
       "     converged_iter  final_objective  \\\n",
       "0             11000     4.966088e-04   \n",
       "1             11000     4.962833e-04   \n",
       "2             11000     3.583341e-06   \n",
       "3             11000    -5.723917e-05   \n",
       "4             11000    -3.638080e-03   \n",
       "..              ...              ...   \n",
       "155           11000     1.060783e+07   \n",
       "156           11000     1.856815e+09   \n",
       "157           11000     1.362941e+08   \n",
       "158           11000     1.593999e+07   \n",
       "159           11000     2.209946e+09   \n",
       "\n",
       "                                       final_portfolio  portfolio_return  \n",
       "0    [0.6745018704862605, 0.6141752435072398, -0.28...          0.002649  \n",
       "1    [0.6750016447446546, 0.6137394069694466, -0.28...          0.002650  \n",
       "2    [1.2697421550470593, 0.9275339761371483, -1.19...          0.005212  \n",
       "3    [1.3346661236282955, 0.9702820869689304, -1.30...          0.005506  \n",
       "4    [6.946014648591141, 3.3590638223388023, -9.305...          0.028748  \n",
       "..                                                 ...               ...  \n",
       "155  [-142.38408408662656, -161.69058299251708, 305...         -0.755969  \n",
       "156  [25016.68903235549, 28419.948008131727, -53435...        132.720764  \n",
       "157  [1836.769624181739, 2086.7015462514073, -3922....          9.744059  \n",
       "158  [215.2839079913253, 244.63441958252952, -458.9...          1.141572  \n",
       "159  [29774.283339476537, 33824.75294087074, -63598...        157.961289  \n",
       "\n",
       "[160 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[\"portfolio_return\"] = result_df.final_portfolio.apply(\n",
    "    lambda x : benchmark(ret_test, price_test, x)[1]\n",
    ")\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.converged.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>pi</th>\n",
       "      <th>backtrack</th>\n",
       "      <th>momentum</th>\n",
       "      <th>step_size/step_eps</th>\n",
       "      <th>converged</th>\n",
       "      <th>converged_iter</th>\n",
       "      <th>final_objective</th>\n",
       "      <th>final_portfolio</th>\n",
       "      <th>portfolio_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>-0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>-0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>-0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>-0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>-0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>True</td>\n",
       "      <td>245</td>\n",
       "      <td>13.377220</td>\n",
       "      <td>[0.913184716035698, 0.1750406748279369, -0.088...</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>13.377220</td>\n",
       "      <td>[0.9131847173588028, 0.17504067382514518, -0.0...</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>156</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>[0.9163616453876688, 0.17405784473782124, -0.0...</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>7380</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>[1.155724069974253, 0.26562639008778244, -0.42...</td>\n",
       "      <td>0.003736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>2198</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>[1.1543026420997577, 0.3189474959798619, -0.47...</td>\n",
       "      <td>0.003818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     theta   pi  backtrack  momentum  step_size/step_eps  converged  \\\n",
       "57    10.0  6.0       True     False              0.0001       True   \n",
       "51    10.0  4.0      False      True              0.0100       True   \n",
       "52    10.0  4.0      False      True              1.0000       True   \n",
       "90  1000.0  6.0      False      True              0.1000       True   \n",
       "54    10.0  4.0      False     False              0.0100       True   \n",
       "..     ...  ...        ...       ...                 ...        ...   \n",
       "94  1000.0  6.0      False     False              0.0100       True   \n",
       "91  1000.0  6.0      False      True              0.0100       True   \n",
       "56    10.0  6.0       True      True              0.0001       True   \n",
       "24     0.1  6.0       True      True              0.0001       True   \n",
       "17     0.1  4.0       True     False              0.0001       True   \n",
       "\n",
       "    converged_iter  final_objective  \\\n",
       "57               0         0.000000   \n",
       "51               0         0.000000   \n",
       "52               0         0.000000   \n",
       "90               0         0.000000   \n",
       "54               0         0.000000   \n",
       "..             ...              ...   \n",
       "94             245        13.377220   \n",
       "91               2        13.377220   \n",
       "56             156         0.133896   \n",
       "24            7380         0.001207   \n",
       "17            2198         0.000999   \n",
       "\n",
       "                                      final_portfolio  portfolio_return  \n",
       "57                                    [0.0, 0.0, 1.0]         -0.000681  \n",
       "51                                    [0.0, 0.0, 1.0]         -0.000681  \n",
       "52                                    [0.0, 0.0, 1.0]         -0.000681  \n",
       "90                                    [0.0, 0.0, 1.0]         -0.000681  \n",
       "54                                    [0.0, 0.0, 1.0]         -0.000681  \n",
       "..                                                ...               ...  \n",
       "94  [0.913184716035698, 0.1750406748279369, -0.088...          0.002752  \n",
       "91  [0.9131847173588028, 0.17504067382514518, -0.0...          0.002752  \n",
       "56  [0.9163616453876688, 0.17405784473782124, -0.0...          0.002761  \n",
       "24  [1.155724069974253, 0.26562639008778244, -0.42...          0.003736  \n",
       "17  [1.1543026420997577, 0.3189474959798619, -0.47...          0.003818  \n",
       "\n",
       "[65 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[result_df.converged].sort_values(by = \"portfolio_return\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
